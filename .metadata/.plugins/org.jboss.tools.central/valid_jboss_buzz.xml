<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">Byteman 4.0.21 has been released</title><link rel="alternate" href="http://bytemanblog.blogspot.com/2023/04/byteman-4021-has-been-released.html" /><author><name>Andrew Dinn</name></author><id>http://bytemanblog.blogspot.com/2023/04/byteman-4021-has-been-released.html</id><updated>2023-04-14T10:55:00Z</updated><content type="html">  Byteman 4.0.21 is now available from the and from the . It is the latest update release for use on all JDK9+ runtimes up to and including JDK21.   Byteman 4.0.21 is a maintenance release which enables Byteman to be used with JDK21 releases. It also contains one  small bug fixes and a feature enhancement. More details are provided in the and the latest .</content><dc:creator>Andrew Dinn</dc:creator></entry><entry><title>How to deploy Open Policy Agent for API authorization</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/13/how-deploy-open-policy-agent-api-authorization" /><author><name>Jorge Balderas</name></author><id>56531825-292e-470c-866c-833c3e9af210</id><updated>2023-04-13T07:00:00Z</updated><published>2023-04-13T07:00:00Z</published><summary type="html">&lt;p&gt;In this article, we will demonstrate how to deploy Open Policy Agent in server mode into a &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; cluster. We will then set up simple Rego policies to validate a JWT token and provide authorization to specific APIs.&lt;/p&gt; &lt;h2&gt;About Open Policy Agent&lt;/h2&gt; &lt;p&gt;Open Policy Agent (&lt;a href="https://www.openpolicyagent.org/docs/latest/" target="_blank"&gt;OPA&lt;/a&gt;) is a Cloud Native Computing Foundation (CNCF) graduated project. OPA is an open source policy agent ideal for decoupling authorization from cloud-native applications, APIs, &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; resources, and &lt;a href="http://developers.redhat.com/topics/ci-cd"&gt;CI/CD&lt;/a&gt; pipelines, along with other artifacts. OPA uses &lt;a href="https://www.openpolicyagent.org/docs/latest/policy-language/" target="_blank"&gt;Rego&lt;/a&gt;, a declarative language, to define policies as code. Applications and services can use OPA to query, provide an input evaluated against predefined policies, and provide a policy decision, as shown in the Figure 1 diagram.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/opa-flow.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/opa-flow.png?itok=KFORdeWg" width="600" height="450" alt="A diagram depicting the flow for evaluating policies by Open Policy Agent." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The flow for evaluating policies by Open Policy Agent.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;How to deploy OPA using REST API&lt;/h2&gt; &lt;p&gt;OPA provides 3 primary &lt;a href="https://www.openpolicyagent.org/docs/latest/integration/#comparison" target="_blank"&gt;options&lt;/a&gt; of deploying OPA to evaluate policies:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;&lt;strong&gt;REST API:&lt;/strong&gt; Deployed separate from your application or service.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Go library:&lt;/strong&gt; Requires Go to deploy as a side car alongside your application.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;WebAssembly (WASM):&lt;/strong&gt; Deployed alongside your application regardless of the language.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;In this article, we will demonstrate the REST API option and focus on the use cases for leveraging OPA for API authorization. We will describe each step for deploying OPA, creating simple policies, and then evaluating the using the OPA REST API.&lt;/p&gt; &lt;h3&gt;Prerequisites&lt;/h3&gt; &lt;p&gt;To complete this demo you will need the following prerequisites:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Red Hat OpenShift cluster:&lt;/strong&gt; For this demo, we use OCP 4.12. However, any 4.x version should work. Alternatively, you can use any Kubernetes cluster. The instructions in this demo are specific to OpenShift.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;OpenShift CLI:&lt;/strong&gt; You can download the OpenShift CLI (&lt;code&gt;oc&lt;/code&gt;) from your cluster as specified in the &lt;a href="https://docs.openshift.com/container-platform/4.12/cli_reference/openshift_cli/getting-started-cli.html" target="_blank"&gt;OpenShift documentation&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Git bash or shell/bash terminal:&lt;/strong&gt; Although not required, the commands presented in this article assume a Linux shell syntax.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Deploying OPA in 2 steps&lt;/h3&gt; &lt;p&gt;To deploy OPA as a REST API, first create three Kubernetes resources.&lt;/p&gt; &lt;h4&gt;Step 1: Create Kubernetes definition files&lt;/h4&gt; &lt;p&gt;Create a file named &lt;strong&gt;deployment.yaml&lt;/strong&gt; with the following content:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: apps/v1 kind: Deployment metadata: name: opa spec: replicas: 1 selector: matchLabels: app: opa template: metadata: labels: app: opa spec: containers: - name: opa securityContext: capabilities: drop: ["ALL"] runAsNonRoot: true allowPrivilegeEscalation: false seccompProfile: type: "RuntimeDefault" image: openpolicyagent/opa:0.50.1-debug args: - "run" - "--watch" - "--ignore=.*" - "--server" - "--skip-version-check" - "--log-level" - "debug" - "--set=status.console=true" - "--set=decision_logs.console=true" &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Most of these parameters are optional, but we included them for higher verbosity level which is helpful for troubleshooting. You can view the purpose of these parameters in the documentation for the &lt;a href="https://www.openpolicyagent.org/docs/latest/cli/#opa-run" target="_blank"&gt;&lt;strong&gt;opa run&lt;/strong&gt;&lt;/a&gt; command.&lt;/p&gt; &lt;p&gt;Important observations:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;We are using OPA version 0.50.1, the latest available at the time of writing. We are using the &lt;code&gt;-debug&lt;/code&gt; version of the OPA image which includes a CLI that can be useful for inspecting the deployed files. However for a production release it is recommended that you use the &lt;code&gt;-rootless&lt;/code&gt; version of this image.&lt;/li&gt; &lt;li&gt;The &lt;code&gt;--server&lt;/code&gt; parameter is what tells OPA to run in server mode so that it can listen for REST API requests.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Next, create a file named &lt;strong&gt;service.yaml&lt;/strong&gt; which will expose OPA as a service within the cluster as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;kind: Service apiVersion: v1 metadata: labels: app: opa name: opa spec: selector: app: opa ports: - name: http protocol: TCP port: 80 targetPort: 8181&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Finally, create a file named &lt;strong&gt;route.yaml&lt;/strong&gt; which will expose OPA service as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;kind: Route apiVersion: route.openshift.io/v1 metadata: labels: app: opa name: opa spec: selector: matchLabels: app: opa to: kind: Service name: opa port: targetPort: http&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We are using http for demo purposes. In a production environment, ensure that you are using https.&lt;/p&gt; &lt;h4&gt;Step 2: Deploy Kubernetes resources to OpenShift cluster&lt;/h4&gt; &lt;p&gt;First, log in to your OpenShift cluster by obtaining a token from your cluster using the OC CLI as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc login --token=&lt;sha256~token&gt; --server=&lt;your-openshift-cluster-api-url&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, create a new project for this cluster. We export the &lt;code&gt;NAMESPACE&lt;/code&gt; name as a variable so that it can be used in subsequent steps.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;NAMESPACE=opa oc new-project $NAMESPACE&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, create the resources using the files created previously as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -f deployment.yaml -n $NAMESPACE oc apply -f service.yaml -n $NAMESPACE oc apply -f route.yaml -n $NAMESPACE&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To get the route that was created, issue the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;echo http://$(oc get route $NAMESPACE -o jsonpath='{.spec.host}')&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Navigate to the route in your browser to view the OPA home screen (Figure 2), which allows you to evaluate a policy.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/opa-home.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/opa-home.png?itok=cqmISo-t" width="600" height="742" alt="A screenshot of the OPA home screen." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The OPA home screen.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Policy evaluation 3-step demo&lt;/h3&gt; &lt;p&gt;Now, we need to define and load policies for demo purposes.&lt;/p&gt; &lt;h4&gt;Step 1: Create common JWT policy&lt;/h4&gt; &lt;p&gt;One of the nice features about Rego is that it provides several &lt;a href="https://www.openpolicyagent.org/docs/latest/policy-reference/#built-in-functions" target="_blank"&gt;built-in functions&lt;/a&gt;. One set of functions that is particularly helpful is the one for JWT (JSON Web Token) &lt;a href="https://www.openpolicyagent.org/docs/latest/policy-reference/#tokens" target="_blank"&gt;token validation&lt;/a&gt;. The policy will decode a JWT token, and then validate it against the secret used to sign the token.&lt;/p&gt; &lt;p&gt;We will use a shared secret for demo purposes. However, the JWT function can verify the token using &lt;a href="https://redthunder.blog/2017/06/08/jwts-jwks-kids-x5ts-oh-my/" target="_blank"&gt;JWKS&lt;/a&gt; (JSON Web Key Sets). Anybody familiar with the JWKS verification flow knows that it is not a trivial implementation. The built-in verify token functions will take care of retrieving KIDs (key ids) from the corresponding well known URL, and it even provides caching capabilities to speed up that process.&lt;/p&gt; &lt;p&gt;First, create a file named &lt;code&gt;jwt.rego&lt;/code&gt;as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;package com.redhat.common.jwt import input import future.keywords.in valid_token(jwt) = token { [header, payload, sig]:= io.jwt.decode(jwt) valid := io.jwt.verify_hs256(jwt, 'secret') token := {"valid": valid, "name": payload.name} }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As you can see from this Rego file, it is primarily JSON, except for the import/package headers. Again, we are using a shared secret, which is done only for demo purposes.&lt;/p&gt; &lt;p&gt;Next, load this policy using the &lt;a href="https://www.openpolicyagent.org/docs/latest/rest-api/#create-or-update-a-policy" target="_blank"&gt;create policy&lt;/a&gt; REST API from the OPA as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;OPA_URL=http://$(oc get route $NAMESPACE -o jsonpath='{.spec.host}') cat jwt.rego | curl --location --request PUT "${OPA_URL}/v1/policies/com/redhat/common/jwt" --header 'Content-Type: text/plain' --data-binary '@-'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Deconstructing this URL:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;${OPA_URL}&lt;/code&gt;: The base OPA URL.&lt;/li&gt; &lt;li&gt;&lt;code&gt;v1/policies&lt;/code&gt;: The default location for policies.&lt;/li&gt; &lt;li&gt;&lt;code&gt;com/redhat/common/jwt&lt;/code&gt;: This is how policies are retrieved. Notice that it matches the package name (i.e., &lt;code&gt;com.redhat.common.jwt&lt;/code&gt;), but using a different character separator. There is no hard rule that these should match, but I have found it a good practice to follow to make it easier to organize policies.&lt;/li&gt; &lt;/ul&gt;&lt;h4&gt;Step 2: Create API authorization policy&lt;/h4&gt; &lt;p&gt;In this step, we will create a policy that uses the common JWT policy loaded in step 1. Create a file named &lt;code&gt;api.rego&lt;/code&gt; with the following content:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;package com.redhat.myapi import data.com.redhat.common.jwt.valid_token default allow := { #disallow requests by default "allowed": false, "reason": "unauthorized resource access" } allow := { "allowed": true } { #allow GET requests to viewer user input.method == "GET" input.path[1] == "policy" token := valid_token(input.identity) token.name == "viewer" token.valid } allow := { "allowed": true } { #allow POST requests to admin user input.method == "POST" input.path[1] == "policy" token := valid_token(input.identity) token.name == "admin" token.valid }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Notice the import to the &lt;code&gt;valid_token&lt;/code&gt; function. It matches the package used previously, but it is prepended with &lt;code&gt;data&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Next, load this policy with a similar &lt;code&gt;curl&lt;/code&gt; command as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;cat api.rego | curl --location --request PUT "${OPA_URL}/v1/policies/com/redhat/myapi" --header 'Content-Type: text/plain' --data-binary '@-'&lt;/code&gt;&lt;/pre&gt; &lt;h4&gt;Step 3: Evaluate the policy&lt;/h4&gt; &lt;p&gt;To evaluate the policy, we will need to get a valid JWT token. You can get one from &lt;a href="http://jwt.io" target="_blank"&gt;jwt.io&lt;/a&gt;, the only requirement is that you enter the same secret from the &lt;strong&gt;jwt&lt;/strong&gt; policy into the &lt;strong&gt;&lt;your-256-bit-secret&gt;&lt;/strong&gt; in the &lt;strong&gt;Verify Signature&lt;/strong&gt; section.&lt;/p&gt; &lt;p&gt;Additionally, change the name in the &lt;strong&gt;Payload&lt;/strong&gt; section to &lt;code&gt;viewer&lt;/code&gt; and copy the generated token.&lt;/p&gt; &lt;p&gt;Repeat these steps and enter &lt;strong&gt;admin&lt;/strong&gt; as the name, and then save both tokens in a file from where you can copy values.&lt;/p&gt; &lt;p&gt;Next, create a request to test a successful viewer request named &lt;code&gt;viewer-allowed.json&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;{ "input": { "identity": "&lt;viewer token&gt;", "path": "policy", "method": "GET" } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Execute the curl command (notice the url changes from &lt;strong&gt;policy&lt;/strong&gt; to &lt;strong&gt;data&lt;/strong&gt;):&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;cat viewer-not-allowed.json | curl --location --request POST "${OPA_URL}/v1/data/com/redhat/myapi" --header 'Content-Type: application/json' --data-binary '@-'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Expect an &lt;strong&gt;allowed true&lt;/strong&gt; output similar to the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;{ "result": { "allow": { "allowed": true } } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, create a request to test a not allowed viewer request named &lt;code&gt;viewer-not-allowed.json&lt;/code&gt; by changing the method to &lt;strong&gt;POST.&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;{ "input": { "identity": "&lt;viewer token&gt;", "path": "policy", "method": "POST" } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Execute the following curl command and expect the output to include &lt;strong&gt;allowed false&lt;/strong&gt;.&lt;/p&gt; &lt;pre&gt; &lt;code&gt;cat viewer-not-allowed.json | curl --location --request POST "${OPA_URL}/v1/data/com/redhat/myapi" --header 'Content-Type: application/json' --data-binary '@-' {"result":{"allow":{"allowed":false,"reason":"unauthorized resource access"}}&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, create an &lt;code&gt;admin-allowed.json&lt;/code&gt; file with the following request:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;{ "input": { "identity": "&lt;admin jwt token&gt;", "path": "policy", "method": "POST" } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Execute the curl command and expect the output to include &lt;strong&gt;allowed true&lt;/strong&gt; as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;cat admin-allowed.json | curl --location --request POST "${OPA_URL}/v1/data/com/redhat/myapi" --header 'Content-Type: application/json' --data-binary '@-'&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Open Policy Agent easily deployed&lt;/h2&gt; &lt;p&gt;This article demonstrated how to easily deploy the Open Policy Agent into an OpenShift cluster and load a common JWT policy with an API policy. We also described how policy evaluation works within OPA. This demo showcased a small set of the capabilities and potential that OPA offers, providing an introduction to OPA and Rego policies.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/13/how-deploy-open-policy-agent-api-authorization" title="How to deploy Open Policy Agent for API authorization"&gt;How to deploy Open Policy Agent for API authorization&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Jorge Balderas</dc:creator><dc:date>2023-04-13T07:00:00Z</dc:date></entry><entry><title>Why you should use io_uring for network I/O</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/12/why-you-should-use-iouring-network-io" /><author><name>Donald Hunter</name></author><id>0b396414-89e5-49a9-8932-b7604cb3ba2d</id><updated>2023-04-12T07:00:00Z</updated><published>2023-04-12T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;code&gt;io_uring&lt;/code&gt; is an async interface to the &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt; kernel that can potentially benefit networking. It has been a big win for file I/O (input/output), but might offer only modest gains for network I/O, which already has non-blocking APIs. The gains are likely to come from the following:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;A reduced number of syscalls on servers that do a lot of context switching&lt;/li&gt; &lt;li aria-level="1"&gt;A unified asynchronous API for both file and network I/O&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Many &lt;code&gt;io_uring&lt;/code&gt; features will soon be available in &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; 9.3, which is distributed with kernel version 5.14. The latest &lt;code&gt;io_uring&lt;/code&gt; features are currently available in Fedora 37.&lt;/p&gt; &lt;h2&gt;What is io_uring?&lt;/h2&gt; &lt;p&gt;&lt;code&gt;io_uring&lt;/code&gt; is an asynchronous I/O interface for the Linux kernel. An &lt;code&gt;io_uring&lt;/code&gt; is a pair of ring buffers in shared memory that are used as queues between user space and the kernel:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Submission queue (SQ): A user space process uses the submission queue to send asynchronous I/O requests to the kernel.&lt;/li&gt; &lt;li&gt;Completion queue (CQ): The kernel uses the completion queue to send the results of asynchronous I/O operations back to user space.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The diagram in Figure 1 shows how &lt;code&gt;io_uring&lt;/code&gt; provides an asynchronous interface between user space and the Linux kernel.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/uring_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/uring_0.png?itok=kNKFe-On" width="600" height="397" alt="Two ring buffers called the submission queue and the completion queue. An application is adding an item to the tail of the submission queue and the kernel is consuming an item from the head of the submission queue. The completion queue shows the reverse for responses from kernel to application." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-creator field--type-string field--label-inline field__items"&gt; &lt;span class="field__label"&gt;Creator&lt;/span&gt; &lt;span class="rhd-media-creator field__item"&gt;Donald Hunter&lt;/span&gt; &lt;/span&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: A visual representation of the io_uring submission and completion queues.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This interface enables applications to move away from the traditional readiness-based model of I/O to a new completion-based model where async file and network I/O share a unified API.&lt;/p&gt; &lt;h2&gt;The syscall API&lt;/h2&gt; &lt;p&gt;The Linux kernel API for &lt;code&gt;io_uring&lt;/code&gt; has 3 syscalls:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;io_uring_setup&lt;/code&gt;: Set up a context for performing asynchronous I/O&lt;/li&gt; &lt;li&gt;&lt;code&gt;io_uring_register&lt;/code&gt;: Register files or user buffers for asynchronous I/O&lt;/li&gt; &lt;li&gt;&lt;code&gt;io_uring_enter&lt;/code&gt;: Initiate and/or complete asynchronous I/O&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The first two syscalls are used to set up an &lt;code&gt;io_uring&lt;/code&gt; instance and optionally to pre-register buffers that would be referenced by &lt;code&gt;io_uring&lt;/code&gt; operations. Only &lt;code&gt;io_uring_enter&lt;/code&gt; needs to be called for queue submission and consumption. The cost of an &lt;code&gt;io_uring_enter&lt;/code&gt; call can be amortized over several I/O operations. For very busy servers, you can avoid &lt;code&gt;io_uring_enter&lt;/code&gt; calls entirely by enabling busy-polling of the submission queue in the kernel. This comes at the cost of a kernel thread consuming CPU.&lt;/p&gt; &lt;h2&gt;The liburing API&lt;/h2&gt; &lt;p&gt;The liburing library provides a convenient way to use &lt;code&gt;io_uring&lt;/code&gt;, hiding some of the complexity and providing functions to prepare all types of I/O operations for submission.&lt;/p&gt; &lt;p&gt;A user process creates an &lt;code&gt;io_uring&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;struct io_uring ring; io_uring_queue_init(QUEUE_DEPTH, &amp;ring, 0);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;then submits operations to the &lt;code&gt;io_uring&lt;/code&gt; submission queue:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;struct io_uring_sqe *sqe = io_uring_get_sqe(&amp;ring); io_uring_prep_readv(sqe, client_socket, iov, 1, 0); io_uring_sqe_set_data(sqe, user_data); io_uring_submit(&amp;ring);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The process waits for completion:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;struct io_uring_cqe *cqe; int ret = io_uring_wait_cqe(&amp;ring, &amp;cqe);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and uses the response:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;user_data = io_uring_cqe_get_data(cqe); if (cqe-&gt;res &lt; 0) {     // handle error } else {     // handle response } io_uring_cqe_seen(&amp;ring, cqe);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The liburing API is the preferred way to use &lt;code&gt;io_uring&lt;/code&gt; from applications. liburing has feature parity with the latest kernel &lt;code&gt;io_uring&lt;/code&gt; development work and is backward-compatible with older kernels that lack the latest &lt;code&gt;io_uring&lt;/code&gt; features.&lt;/p&gt; &lt;h2&gt;Using io_uring for network I/O&lt;/h2&gt; &lt;p&gt;We will try out &lt;code&gt;io_uring&lt;/code&gt; for network I/O by writing a simple echo server using the liburing API. Then we will see how to minimize the number of syscalls required for a high-rate concurrent workload.&lt;/p&gt; &lt;h3&gt;A simple echo server&lt;/h3&gt; &lt;p&gt;The classic echo server that appeared in Berkeley Software Distribution (BSD) Unix looks something like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;client_fd = accept(listen_fd, &amp;client_addr, &amp;client_addrlen); for (;;) {     numRead = read(client_fd, buf, BUF_SIZE);     if (numRead &lt;= 0)   // exit loop on EOF or error         break;     if (write(client_fd, buf, numRead) != numRead)         // handle write error     } } close(client_fd);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The server could be multithreaded or use non-blocking I/O to support concurrent requests. Whatever form it takes, the server requires at least 5 syscalls per client session, for accept, read, write, read to detect EOF and then close.&lt;/p&gt; &lt;p&gt;A naive translation of this to &lt;code&gt;io_uring&lt;/code&gt; results in an asynchronous server that submits one operation at a time and waits for completion before submitting the next. The pseudocode for a simple &lt;code&gt;io_uring&lt;/code&gt;-based server, omitting the boilerplate and error handling, looks like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;add_accept_request(listen_socket, &amp;client_addr, &amp;client_addr_len); io_uring_submit(&amp;ring); while (1) {     int ret = io_uring_wait_cqe(&amp;ring, &amp;cqe);     struct request *req = (struct request *) cqe-&gt;user_data;     switch (req-&gt;type) {     case ACCEPT:         add_accept_request(listen_socket,                           &amp;client_addr, &amp;client_addr_len);         add_read_request(cqe-&gt;res);         io_uring_submit(&amp;ring);         break;     case READ:         if (cqe-&gt;res &lt;= 0) {             add_close_request(req);         } else {             add_write_request(req);         }         io_uring_submit(&amp;ring);         break;     case WRITE:         add_read_request(req-&gt;socket);         io_uring_submit(&amp;ring);         break;     case CLOSE:         free_request(req);         break;     default:         fprintf(stderr, "Unexpected req type %d\n", req-&gt;type);         break;     }     io_uring_cqe_seen(&amp;ring, cqe); }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this &lt;code&gt;io_uring&lt;/code&gt; example, the server still requires at least 4 syscalls to process each new client. The only saving achieved here is by submitting a read and a new accept request together. This can be seen in the following strace output for the echo server receiving 1,000 client requests.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;% time     seconds  usecs/call     calls    errors syscall ------ ----------- ----------- --------- --------- ---------------- 99.99    0.445109         111      4001           io_uring_enter   0.01    0.000063          63         1           brk ------ ----------- ----------- --------- --------- ---------------- 100.00    0.445172         111      4002           total&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Combining submissions&lt;/h3&gt; &lt;p&gt;In an echo server, there are limited opportunities for chaining I/O operations since we need to complete a read before we know how many bytes we can write. We could chain accept and read by using a new fixed file feature of &lt;code&gt;io_uring&lt;/code&gt;, but we’re already able to submit a read request and a new accept request together, so there’s maybe not much to be gained there.&lt;/p&gt; &lt;p&gt;We can submit independent operations at the same time so we can combine the submission of a write and the following read. This reduces the syscall count to 3 per client request:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;% time     seconds  usecs/call     calls    errors syscall ------ ----------- ----------- --------- --------- ---------------- 99.93    0.438697         146      3001           io_uring_enter   0.07    0.000325         325         1           brk ------ ----------- ----------- --------- --------- ---------------- 100.00    0.439022         146      3002           total&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Draining the completion queue&lt;/h3&gt; &lt;p&gt;It is possible to combine a lot more work into the same submission if we handle all queued completions before calling &lt;code&gt;io_uring_submit&lt;/code&gt;. We can do this by using a combination of &lt;code&gt;io_uring_wait_cqe&lt;/code&gt; to wait for work, followed by calls to &lt;code&gt;io_uring_peek_cqe&lt;/code&gt; to check whether the completion queue has more entries that can be processed. This avoids spinning in a busy loop when the completion queue is empty while also draining the completion queue as fast as possible.&lt;/p&gt; &lt;p&gt;The pseudocode for the main loop now looks like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;while (1) {     int submissions = 0;     int ret = io_uring_wait_cqe(&amp;ring, &amp;cqe);     while (1) {         struct request *req = (struct request *) cqe-&gt;user_data;         switch (req-&gt;type) {         case ACCEPT:             add_accept_request(listen_socket,                               &amp;client_addr, &amp;client_addr_len);             add_read_request(cqe-&gt;res);             submissions += 2;             break;         case READ:             if (cqe-&gt;res &lt;= 0) {                 add_close_request(req);                 submissions += 1;             } else {                 add_write_request(req);                 add_read_request(req-&gt;socket);                 submissions += 2;             }             break;         case WRITE:           break;         case CLOSE:             free_request(req);             break;         default:             fprintf(stderr, "Unexpected req type %d\n", req-&gt;type);             break;         }         io_uring_cqe_seen(&amp;ring, cqe);         if (io_uring_sq_space_left(&amp;ring) &lt; MAX_SQE_PER_LOOP) {             break;     // the submission queue is full         }         ret = io_uring_peek_cqe(&amp;ring, &amp;cqe);         if (ret == -EAGAIN) {             break;     // no remaining work in completion queue         }     }     if (submissions &gt; 0) {         io_uring_submit(&amp;ring);     } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result of batching submissions for all available work gives a significant improvement over the previous result, as shown in the following strace output, again for 1,000 client requests:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;% time     seconds  usecs/call     calls    errors syscall ------ ----------- ----------- --------- --------- ---------------- 99.91    0.324226        4104        79           io_uring_enter   0.09    0.000286         286         1           brk ------ ----------- ----------- --------- --------- ---------------- 100.00    0.324512        4056        80           total&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The improvement here is substantial, with more than 12 client requests being handled per syscall, or an average of more than 60 I/O ops per syscall. This ratio improves as the server gets busier, which can be demonstrated by enabling logging in the server:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;% time     seconds  usecs/call     calls    errors syscall ------ ----------- ----------- --------- --------- ---------------- 68.86    0.225228          42      5308       286 write 31.13    0.101831        4427        23           io_uring_enter   0.00    0.000009           9         1           brk ------ ----------- ----------- --------- --------- ---------------- 100.00    0.327068          61      5332       286 total&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This shows that when the server has more work to do, more &lt;code&gt;io_uring&lt;/code&gt; operations have time to complete so more new work can be submitted in a single syscall. The echo server is responding to 1,000 client echo requests, or completing 5,000 socket I/O operations with just 23 syscalls.&lt;/p&gt; &lt;p&gt;It is worth noting that as the amount of work submitted increases, the time spent in the &lt;code&gt;io_uring_enter&lt;/code&gt; syscall increases, too. There will come a point where it might be necessary to limit the size of submission batches or to enable submission queue polling in the kernel.&lt;/p&gt; &lt;h2&gt;Benefits of network I/O&lt;/h2&gt; &lt;p&gt;The main benefit of &lt;code&gt;io_uring&lt;/code&gt; for network I/O is a modern asynchronous API that is straightforward to use and provides unified semantics for file and network I/O.&lt;/p&gt; &lt;p&gt;A potential performance benefit of &lt;code&gt;io_uring&lt;/code&gt; for network I/O is reducing the number of syscalls. This could provide the biggest benefit for high volumes of small operations where the syscall overhead and number of context switches can be significantly reduced.&lt;/p&gt; &lt;p&gt;It is also possible to avoid cumulatively expensive operations on busy servers by pre-registering resources with the kernel before sending &lt;code&gt;io_uring&lt;/code&gt; requests. File slots and buffers can be registered to avoid the lookup and refcount costs for each I/O operation.&lt;/p&gt; &lt;p&gt;Registered file slots, called fixed files, also make it possible to chain an accept with a read or write, without any round-trip to user space. A submission queue entry (SQE) would specify a fixed file slot to store the return value of accept, which a linked SQE would then reference in an I/O operation.&lt;/p&gt; &lt;h2&gt;Limitations&lt;/h2&gt; &lt;p&gt;In theory, operations can be chained together using the &lt;code&gt;IOSQE_IO_LINK&lt;/code&gt; flag. However, for reads and writes, there is no mechanism to coerce the return value from a read operation into the parameter set for the following write operation. This limits the scope of linked operations to semantic sequencing such as "write then read" or “write then close” and for accept followed by read or write.&lt;/p&gt; &lt;p&gt;Another consideration is that &lt;code&gt;io_uring&lt;/code&gt; is a relatively new Linux kernel feature that is still under active development. There is room for performance improvement, and some &lt;code&gt;io_uring&lt;/code&gt; features might still benefit from optimization work. &lt;/p&gt; &lt;p&gt;&lt;code&gt;io_uring&lt;/code&gt; is currently a Linux-specific API, so integrating it into cross-platform libraries like libuv could present some challenges.&lt;/p&gt; &lt;h2&gt;Latest features&lt;/h2&gt; &lt;p&gt;The most recent features to arrive in &lt;code&gt;io_uring&lt;/code&gt; are multi-shot accept, which is available from 5.19 and multi-shot receive, which arrived in 6.0. Multi-shot accept allows an application to issue a single accept SQE, which will repeatedly post a CQE whenever the kernel receives a new connection request. Multi-shot receive will likewise post a CQE whenever newly received data is available. These features are available in Fedora 37 but are not yet available in RHEL 9.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;io_uring&lt;/code&gt; API is a fully functional asynchronous I/O interface that provides unified semantics for both file and network I/O. It has the potential to provide modest performance benefits to network I/O on its own and greater benefit for mixed file and network I/O application workloads.&lt;/p&gt; &lt;p&gt;Popular asynchronous I/O libraries such as libuv are multi-platform, which makes it more challenging to adopt Linux-specific APIs. When adding &lt;code&gt;io_uring&lt;/code&gt; to a library, both file I/O and network I/O should be added to gain the most from io_uring's async completion model.&lt;/p&gt; &lt;p&gt;Network I/O-related feature development and optimization work in &lt;code&gt;io_uring&lt;/code&gt; will be driven primarily by further adoption in networked applications. Now is the time to integrate &lt;code&gt;io_uring&lt;/code&gt; into your applications and I/O libraries.&lt;/p&gt; &lt;h2&gt;More information&lt;/h2&gt; &lt;p&gt;Explore the following resources to learn more: &lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://kernel-recipes.org/en/2019/talks/faster-io-through-io_uring/"&gt;Faster IO through io_uring&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://https://kernel.dk/io_uring.pdf"&gt;Detailed description (PDF)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://lwn.net/Articles/863071/"&gt;Fixed files&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://kernel.dk/axboe-kr2022.pdf"&gt;What’s new (PDF)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/axboe/liburing/wiki/io_uring-and-networking-in-2023"&gt;io_uring and networking in 2023&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Find other tutorials on Red Hat Developer's &lt;a href="http://developers.redhat.com/topics/linux/"&gt;Linux topic page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/12/why-you-should-use-iouring-network-io" title="Why you should use io_uring for network I/O"&gt;Why you should use io_uring for network I/O&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Donald Hunter</dc:creator><dc:date>2023-04-12T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus Newsletter #31 - April</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-newsletter-31/" /><author><name>James Cobb</name></author><id>https://quarkus.io/blog/quarkus-newsletter-31/</id><updated>2023-04-12T00:00:00Z</updated><content type="html">It’s time for the April Newsletter. Read Willem Meints’s article "Quarkus: Jave revisited!" where shares his experience with Java using Quarkus after a long hiatus. Learn why Sebastian Daschner thinks Quarkus is a great choice for Enterprise Java in his great video. Learn how to deploy a Quarkus application to...</content><dc:creator>James Cobb</dc:creator></entry><entry><title type="html">How to configure WildFly with YAML files</title><link rel="alternate" href="https://www.mastertheboss.com/jbossas/jboss-configuration/how-to-configure-wildfly-with-yaml-files/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/jbossas/jboss-configuration/how-to-configure-wildfly-with-yaml-files/</id><updated>2023-04-11T12:40:48Z</updated><content type="html">WildFly 28 includes support for YAML configuration which is offers a more flexible approach in some use cases. In this tutorial we will discuss which are the best scenarios where YAML configuration is a perfect fit and how to configure WildFly to use YAML files Why YAML Files? One of the main advantages of YAML ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Deploy React applications to OpenShift</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/11/deploy-react-apps-openshift" /><author><name>Yashwanth Maheshwaram</name></author><id>4a539055-118b-4d0e-b83e-334df1be8d12</id><updated>2023-04-11T07:00:00Z</updated><published>2023-04-11T07:00:00Z</published><summary type="html">&lt;p&gt;React is an open-source &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; library for building user interfaces. It allows developers to create reusable UI components and efficiently update the view in response to changes in data. &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; enables developers to build, deploy, run, and manage a wide variety of applications, including frontend and the ones made with React. React applications use the &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; runtime to run the application.&lt;/p&gt; &lt;p&gt;This article will help you get started with ReactJS apps on OpenShift. You will learn how to:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Deploy a basic React application from the ground up in the easiest way possible without having to deal with &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; and a lot of other complications that come with it.&lt;/li&gt; &lt;li aria-level="1"&gt;Manage product and development environments for a React application.&lt;/li&gt; &lt;li aria-level="1"&gt;Add &lt;a href="developers.redhat.com/topics/ci-cd"&gt;continuous deployment (CD)&lt;/a&gt; to your React application to automatically deploy updates to your repository.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;Node.js is required for your machine to be able to build and run React applications on your local machine. Install &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt;  via one of the following options: &lt;/p&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;If you are using &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL): &lt;a href="https://access.redhat.com/products/nodejs"&gt;https://access.redhat.com/products/nodejs&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;If you're using any other operating system: &lt;a href="https://nodejs.org/en/"&gt;https://nodejs.org/en/&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Create a sample React application&lt;/h2&gt; &lt;p&gt;Create React App is a comfortable environment for learning React, and it is the best way to start building a new single-page application in React. It sets up your development environment so that you can use the latest JavaScript features, provides a nice developer experience, and optimizes your app for production.&lt;/p&gt; &lt;p&gt;You’ll need to have Node 14.0.0+ and npm 5.6+ on your machine. If you want to use a readily available example application, skip this step and move to the Deploy section.&lt;/p&gt; &lt;p&gt;To create a project, run:&lt;/p&gt; &lt;pre class="hljs"&gt; npx create-react-&lt;span class="hljs-keyword"&gt;app my-&lt;span class="hljs-keyword"&gt;app &lt;span class="hljs-keyword"&gt;cd my-&lt;span class="hljs-keyword"&gt;app npm start&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; &lt;h2&gt;Publish your code to Git&lt;/h2&gt; &lt;p&gt;Create a repository on GitHub or any other Git platform. If you want to use a &lt;a href="https://github.com/yashwanthm/react-openshift-example"&gt;readily available example application&lt;/a&gt;, copy the URL and move on to the next step: &lt;code&gt;https://github.com/yashwanthm/react-openshift-example&lt;/code&gt;&lt;/p&gt; &lt;p&gt;The repository has &lt;a href="https://create-react-app.dev/docs/deployment#customizing-environment-variables-for-arbitrary-build-environments"&gt;a minor recommended change to the usual create-react-app approach&lt;/a&gt; to be able to run a production application.&lt;/p&gt; &lt;p&gt;You will need to run &lt;code&gt;npm run start.development.local&lt;/code&gt; instead of &lt;code&gt;npm start&lt;/code&gt; on your local machine. The rest remains the same.&lt;/p&gt; &lt;h2&gt;Deploy your React application to the OpenShift sandbox&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt; is a free-to-use OpenShift instance for you to experiment with OpenShift for your use cases. It's an excellent way to try running React applications on OpenShift. &lt;/p&gt; &lt;p&gt;Follow these steps to start your sandbox instance and deploy your app:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Create a Sandbox account using &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;https://developers.redhat.com/developer-sandbox&lt;/a&gt; &lt;/li&gt; &lt;li aria-level="1"&gt;Once you have the account, click on &lt;strong&gt;Start using your sandbox.&lt;/strong&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Give it a few seconds and your sandbox instance will load up.&lt;/li&gt; &lt;li aria-level="1"&gt;On the left side menu, click on &lt;strong&gt;+Add&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Select &lt;strong&gt;Import from Git&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Specify your Git repo URL: &lt;code&gt;https://github.com/yashwanthm/react-openshift-example &lt;/code&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;You will now be moved to the Topology view, and the app will start to deploy. Give it about a minute to finish deployment. While it’s deploying, you will be able to view the logs.&lt;/li&gt; &lt;li aria-level="1"&gt;Once it’s done deploying, you can click on the OpenURL button to see the UI of your React application running on OpenShift.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Congratulations! You now have a vanilla React application that runs on OpenShift without having to work with complex configurations that are needed. Read on for details on how to make a change and see the change go live for your application.&lt;/p&gt; &lt;h2&gt;Fork and deploy your own repo&lt;/h2&gt; &lt;p&gt;Now that you tried using the example repository, follow these steps to deploy your own repo:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Fork &lt;code&gt;https://github.com/yashwanthm/react-openshift-example&lt;/code&gt; or create your own repo.&lt;/li&gt; &lt;li aria-level="1"&gt;Copy the URL.&lt;/li&gt; &lt;li aria-level="1"&gt;Log in to the Developer Sandbox.&lt;/li&gt; &lt;li aria-level="1"&gt;Import from Git and use your repository to create an application.&lt;/li&gt; &lt;li aria-level="1"&gt;Access your application.&lt;/li&gt; &lt;li aria-level="1"&gt;Add CD.&lt;/li&gt; &lt;li aria-level="1"&gt;Make changes to the source &lt;code&gt;App.js&lt;/code&gt;, commit, and push.&lt;/li&gt; &lt;li aria-level="1"&gt;See your changes get deployed automatically.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Add continuous deployment&lt;/h2&gt; &lt;p&gt;Continuous deployment is a strategy in software development where code changes to an application are released automatically into the production environment. It speeds up time to market by eliminating the lag between coding and customer value. OpenShift enables developers to configure this using a few simple UI-based steps.&lt;/p&gt; &lt;p&gt;Now, let’s begin adding CD to the application we just created:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Click on Actions.&lt;/li&gt; &lt;li aria-level="1"&gt;Select &lt;strong&gt;Edit &lt;application name&gt;&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Check the &lt;strong&gt;Add pipeline&lt;/strong&gt; checkbox. You can see the pipeline visualization if you’d like to understand the steps.&lt;/li&gt; &lt;li aria-level="1"&gt;Click &lt;strong&gt;Save&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; OpenShift Sandbox will suspend your application when it is idled but will bring back the pod up when there’s a hit to the URL, it takes a few seconds for the application to load. However, this will not be the case on your production OpenShift instance. &lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;OpenShift provides a simplified developer experience for running the applications on the cloud. Explore other popular activities for the sandbox:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/developer-sandbox/activities/how-to-deploy-java-application-in-kubernetes"&gt;Deploy a Java application on Kubernetes in minutes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/developer-sandbox/activities/migrate-and-deploy-cloud-foundry"&gt;Migrate and deploy Cloud Foundry applications to Kubernetes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/node/283511"&gt;Run the Canary Deployment pattern on Kubernetes&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/11/deploy-react-apps-openshift" title="Deploy React applications to OpenShift"&gt;Deploy React applications to OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Yashwanth Maheshwaram</dc:creator><dc:date>2023-04-11T07:00:00Z</dc:date></entry><entry><title>How to deploy single sign-on as code using GitOps</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/10/how-deploy-single-sign-code-using-gitops" /><author><name>Pablo Castelo, Ignacio Lago</name></author><id>163fbb25-7860-4209-9503-300b78ec94e6</id><updated>2023-04-10T07:00:00Z</updated><published>2023-04-10T07:00:00Z</published><summary type="html">&lt;p&gt;In this series of articles, we will demonstrate how to use Git, Argo CD, and Red Hat OpenShift GitOps to build a continuous delivery cycle that automatically synchronizes and deploys different solutions. In this article, we will discuss the &lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;single sign-on for Red Hat solutions&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In the world of &lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt;, where simplicity is tied to complexity, sometimes you can deploy your application with flexible horizontal auto-scaling, out-of-the-box load balancing, distributed management of components, and centralized control of multiple applications. However, with great power comes great responsibilities and complexity.&lt;/p&gt; &lt;p&gt;To help us solve this complexity and take accountability for our newfound power, strategies have been developed for Kubernetes. In this article, we will take a closer look at &lt;a href="http://developers.redhat.com/topics/ci-cd"&gt;continuous integration and continuous deployment (CI/CD)&lt;/a&gt;. These systems usually work with a high level of abstraction to help us solve four common issues: version control, change logging, consistency of deployments, and rollback functionality. One of the most popular approaches to this abstraction layer is called &lt;a href="https://www.redhat.com/en/topics/devops/what-is-gitops"&gt;GitOps&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;GitOps, originally proposed in a Weaveworks &lt;a href="https://www.weave.works/blog/gitops-operations-by-pull-request"&gt;blog post&lt;/a&gt; in 2017, is built around &lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt; implementation. It is a “single source of truth” in CI/CD processes.&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/container-platform"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; is the leading &lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt; platform in GitOps deployments. It comes out of the box with access to &lt;a href="https://operatorframework.io/"&gt;operators&lt;/a&gt; (curated and supported by &lt;a href="https://www.redhat.com"&gt;Red Hat&lt;/a&gt;) that are part of the &lt;a href="https://catalog.redhat.com/software/operators/detail/5fb288c70a12d20cbecc6056"&gt;OpenShift GitOps Operator&lt;/a&gt;. &lt;a href="https://argoproj.github.io/argo-cd"&gt;Argo CD&lt;/a&gt;, a declarative continuous delivery tool, is also part of this.&lt;/p&gt; &lt;p&gt;By having comprehensive management of the deployment and lifecycle of things, it provides solutions for version control, configurations, and application definitions in Kubernetes environments, organizing complex data with an easy-to-understand user interface.&lt;/p&gt; &lt;p&gt;Argo CD has support for common ways of deploying Kubernetes manifests such as &lt;a href="https://kustomize.io/"&gt;Kustomize&lt;/a&gt; applications, &lt;a href="https://helm.sh/"&gt;Helm&lt;/a&gt; charts, and regular YAML/JSON files.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;To start this demonstration, you will need the following:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Red Hat OpenShift cluster&lt;/li&gt; &lt;li aria-level="1"&gt;Admin user&lt;/li&gt; &lt;li aria-level="1"&gt;The tools listed in this table:&lt;/li&gt; &lt;/ul&gt;&lt;div&gt; &lt;table cellspacing="0" width="625"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;&lt;strong&gt;Tools Required&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;macOS&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Linux/Fedora&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Git&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;a href="https://git-scm.com/download/mac"&gt;Download&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;a href="https://git-scm.com/download/linux"&gt;Download&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;OpenShift client 4.11&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;a href="https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/4.11.11/openshift-client-linux-4.11.11.tar.gz"&gt;Download&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;a href="https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/4.11.11/openshift-client-mac-4.11.11.tar.gz"&gt;Download&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Argo CD CLI&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;a href="https://argo-cd.readthedocs.io/en/stable/cli_installation/#download-with-curl"&gt;Download&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;a href="https://argo-cd.readthedocs.io/en/stable/cli_installation/#mac"&gt;Download&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; These tools are available through the &lt;a href="https://docs.openshift.com/container-platform/4.10/web_console/odc-about-web-terminal.html"&gt;Web Terminal Operator&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Install OpenShift GitOps operator and Argo CD instance&lt;/h2&gt; &lt;p&gt;For the scope of this article, we will use the following &lt;a href="https://github.com/ignaciolago/keycloak-gitops"&gt;Git repository&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;git clone https://github.com/ignaciolago/keycloak-gitops cd keycloak-gitops&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To install the OpenShift GitOps operator and Argo CD instance, take a look a the files first as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat 00_argocd_namespace.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We will use this file to create a namespace for our installation:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: v1 kind: Namespace #kubernetes api element kind for namespace metadata: #argocd wave in which the element is synced name: openshift-gitops #default name for the installation in Openshift spec: {}&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Enter the following command for the subscription to install the GitOps operator:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat 01_argocd_subscription.yaml&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: operators.coreos.com/v1alpha1 kind: Subscription # subscription for the Operator, would add it to the operator # this operator installs an argocd instance for default metadata: name: openshift-gitops-operator namespace: openshift-operators spec: channel: latest installPlanApproval: Automatic name: openshift-gitops-operator source: redhat-operators sourceNamespace: openshift-marketplace # startingCSV: openshift-gitops-operator.v1.7.2&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The role binding for the Argo CD instance:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat 02_argocd_rbac.yaml&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 # role base access control binding for argocd permissions metadata: name: argocd-rbac-ca subjects: - kind: ServiceAccount # tied to the argocd service account name: openshift-gitops-argocd-application-controller # since we are using applications we use the argocd application controller namespace: openshift-gitops roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin # in this example we are using cluster-admin but we can give it lesser permissions if needed&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We are using Kustomize to package because it helps with debugging and allows us to reutilize code for multiple environments. We will use this in subsequent articles. We have a &lt;code&gt;kustomization.yaml&lt;/code&gt; file containing the references for all the other files as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat customization.yaml&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - 00_argocd_namespace.yaml - 01_argocd_subscription.yaml - 02_argocd_rbac.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that we understand the files, we will proceed with installing the OpenShift GitOps operator and Argo CD instance. Use the Kustomize flag, &lt;code&gt;-k&lt;/code&gt; or &lt;code&gt;–kustomize&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc apply -k bootstrap/argocd&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As we can see in the following output, the previous command will create three resources for us, the namespace, the role-binding, and the subscription and installation of the operator.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;namespace/openshift-gitops created clusterrolebinding.rbac.authorization.k8s.io/argocd-rbac-ca created subscription.operators.coreos.com/openshift-gitops-operator created&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now we are going to verify that the OpenShift GitOps operator and Argo CD instance components are installed by using the following command to verify the status of the deployments:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ watch oc get pods -n openshift-gitops&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;NAME READY STATUS RESTARTS AGE cluster-54f5bcdc85-5vs57 1/1 Running 0 4m5s kam-7d7bfc8675-xmcdg 1/1 Running 0 4m4s openshift-gitops-application-controller-0 1/1 Running 0 4m2s openshift-gitops-applicationset-controller-5cf7bb9dbc-8qtzl 1/1 Running 0 4m2s openshift-gitops-dex-server-6575c69849-knt27 1/1 Running 0 4m2s openshift-gitops-redis-bb656787d-wglb7 1/1 Running 0 4m2s openshift-gitops-repo-server-54c7998dbf-tglrc 1/1 Running 0 4m2s openshift-gitops-server-786849cbb8-l9npk 1/1 Running 0 4m2s&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Of course, we can also check how the installation is going in the GUI by accessing the OpenShift web console and the Operator Hub (Figure 1):&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image5_2.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image5_2.png?itok=YOExWTLB" width="600" height="363" alt="Installed Operators -&gt; GitOps Operator" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: Check the GitOps operator installation.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Now that the operator is installed, we recover the path of the Argo CD GUI by using the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc get route openshift-gitops-server -n openshift-gitops --template='https://{{.spec.host}}' &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Copy the following URL and paste it into the browser to access the Argo CD login page.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;https://openshift-gitops-server-openshift-gitops.apps.cluster-lvn9g.lvn9g.sandbox1571.opentlc.com​&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Click the &lt;strong&gt;log in via OpenShift&lt;/strong&gt; button.&lt;/p&gt; &lt;p&gt;Then enter your OpenShift credentials.&lt;/p&gt; &lt;p&gt;Proceed to authorize access to Argo CD to the user.&lt;/p&gt; &lt;p&gt;Now that we have added the permissions to our user, we are able to see the Argo CD interface. Now it's time to learn how to deploy applications using it.&lt;/p&gt; &lt;h2&gt;Deploying single sign-on for a dev environment&lt;/h2&gt; &lt;p&gt;For this part, we are going to learn how to automatically install all the components needed to run &lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;single sign-on&lt;/a&gt; (SSO) using GitOps and a Git repository as the source of truth.&lt;/p&gt; &lt;p&gt;We are going to install a namespace-contained installation of SSO using the operator deploying a managed SSO and Postgres installation; for that, let us take a look at the files for this we do:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cd../../resources/01_rhsso-dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We have the namespace yaml like before:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat 00_namespace_rhsso-dev.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Again we create the namespace, but this time for SSO:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- apiVersion: v1 kind: Namespace metadata: annotations: argocd.argoproj.io/sync-wave: "0" # now that we deploying using ArgoCD we can specify the order of deploy name: rhsso-dev spec: {}&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat 01_rhsso-operator_resourcegroups.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Operator group for SSO:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: annotations: argocd.argoproj.io/sync-wave: "1" # Sync Wave 1 since we need to have the namespace first name: rhsso-dev namespace: rhsso-dev spec: targetNamespaces: - rhsso-dev&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat 02_rhsso-operator.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now we will create a subscription for the installation of the operator.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: annotations: argocd.argoproj.io/sync-wave: "2" # sync wave 2 since we need the Namespace and OperatorGroup and so on... name: rhsso-operator namespace: rhsso-dev spec: channel: stable installPlanApproval: Automatic name: rhsso-operator source: redhat-operators sourceNamespace: openshift-marketplace startingCSV: rhsso-operator.7.6.1-opr-005&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat 03_deploy_rhsso-dev.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This file contains the config of the instance that we are going to create inside the operator to install the product.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- apiVersion: keycloak.org/v1alpha1 kind: Keycloak metadata: annotations: argocd.argoproj.io/sync-wave: "3" name: rhsso-dev labels: app: rhsso-dev namespace: rhsso-dev spec: multiAvailablityZones: enabled: true # we add this flag for HA deploy, we need more than 1 pod for this externalAccess: enabled: true keycloakDeploymentSpec: imagePullPolicy: Always postgresDeploymentSpec: imagePullPolicy: Always instances: 2 # we set a minimum of 2 pods for the HA storageClassName: gp2&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat kustomization.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is the Kustomization file that contains all files we will use for this installation.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization commonAnnotations: argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true # To skip the dry run for missing resource types, use the following annotation resources: - 00_namespace_rhsso-dev.yaml - 01_rhsso-operator_resourcegroups.yaml - 02_rhsso-operator.yaml - 03_deploy_rhsso-dev.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that we understand the files that we are going to install, we have to take a look at the Argo CD application that is going to deploy and sync them:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cd../../bootstrap/deploy/application/01_rhsso-dev $ cat 01_rh-sso.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here we can take a look at a regular application for Argo CD; we are going to deploy it in the same namespace as Argo CD and aim it at our Git repository:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- apiVersion: argoproj.io/v1alpha1 kind: Application metadata: annotations: argocd.argoproj.io/sync-wave: "0" name: rhsso-dev namespace: openshift-gitops spec: destination: name: '' namespace: openshift-gitops server: 'https://kubernetes.default.svc' source: path: resources/01_rhsso-dev # we specify the folder for the files repoURL: 'https://github.com/ignaciolago/keycloak-gitops.git' # the repository url targetRevision: HEAD # and branch, in this case HEAD / main project: default syncPolicy: automated: prune: true selfHeal: true syncOptions: - PruneLast=true&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The kustomize file:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat kustomization.yaml &lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization commonAnnotations: argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true resources: - 01_rh-sso.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now we are going to apply all these files to start the installation.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc apply -k bootstrap/deploy/application/01_rhsso-dev&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;application.argoproj.io/rhsso-dev created&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We have to wait for all pods to be in a running state.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ watch oc get pods -n rhsso-dev&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;NAME READY STATUS RESTARTS AGE keycloak-0 0/1 Init:0/1 0 4s keycloak-postgresql-59f5b79f4b-bbck4 0/1 Pending 0 4s rhsso-operator-7d8f749748-hc888 1/1 Running 0 6m56s&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;NAME READY STATUS RESTARTS AGE keycloak-0 1/1 Running 0 4m41s keycloak-1 1/1 Running 0 3m40s keycloak-postgresql-59f5b79f4b-bbck4 1/1 Running 0 5m30s rhsso-operator-7d8f749748-hc888 1/1 Running 0 7m20s&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We can track the process and status updates of the components, as shown in Figure 2.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image3_6.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image3_6.png?itok=dQm4QRLi" width="600" height="293" alt="Observing the status and installation process in Argo CD." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: Track the installation status updates of the components on this Argo CD status page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;When they are all in sync, the status page will appear as in Figure 3.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image7_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image7_0.png?itok=WJD1OuZZ" width="600" height="466" alt="all in Sync Status" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: Status page shows that all processes are in sync.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Once the installation is ready, we have to recover the single sign-on route as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;@oc get route keycloak -n rhsso-dev --template='https://{{.spec.host}}' https://keycloak-rhsso-dev.apps.cluster-lvn9g.lvn9g.sandbox1571.opentlc.com&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We can access the GUI by entering this URL in the browser to verify that it is working (Figure 4).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image8.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/image8.png?itok=yAbM1wyD" width="1391" height="578" alt="Red Hat single sign-on (SSO) login page credentials" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: The SSO login page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;We need the credentials in order to gain access. To recover the credentials for this, we must either use the &lt;code&gt;oc&lt;/code&gt; CLI or the OpenShift GUI to get to the secret and decode it. The secret is called &lt;code&gt;credential-rhsso-dev&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Tip:&lt;/strong&gt; The second part of the name will depend on the name of the instance.&lt;/p&gt; &lt;h3&gt;Recover the credentials from the GUI&lt;/h3&gt; &lt;p&gt;Figure 5 shows the credentials secret details on OpenShift.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image22.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/image22.png?itok=y1vZZjQF" width="1440" height="974" alt="Credentials Secret on Openshift" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: The credentials secret details.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Recover the credentials from the oc CLI&lt;/h3&gt; &lt;p&gt;We can recover the credentials from the oc CLI as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc get secret credential-rhsso-dev -n rhsso-dev -o jsonpath="{.data['ADMIN_PASSWORD']}" | base64 -d&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;n3XViKMKmg_ZFw==&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We will use the credentials to authenticate. After logging in, we can check that everything is working (Figure 6).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image11_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/image11_0.png?itok=Jpum3J18" width="1440" height="540" alt="SSO Already Login" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 6: SSO Master details.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Congratulations, you have successfully deployed a single sign-on using Argo CD!&lt;/p&gt; &lt;h3&gt;Deploy a single sign-on for the product environment&lt;/h3&gt; &lt;p&gt;We cannot use a namespace-contained deployment for production because the database would be running inside a pod—this would be a Single Point Of Failure (SPoF) and we can not allow it! So we will learn how to deploy using an external (and hopefully highly available) database.&lt;/p&gt; &lt;p&gt;First we need to add the following lines to our Keycloak resource like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: keycloak.org/v1alpha1 kind: Keycloak Metadata: {} spec: multiAvailablityZones: enabled: true externalDatabase: ## ADD THIS LINE enabled: true ## ADD THIS LINE &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Take a look at the resources folder and see the files for a prod deploy.&lt;/p&gt; &lt;p&gt;The namespace, operator group, and operator subscription are the same as before, and we can check it by doing the &lt;code&gt;cat&lt;/code&gt; again as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cd../../../../resources/02_rhsso-prod $cat 00_namespace_rhsso-prod.yaml 01_rhsso-operator_resourcegroups.yaml 02_rh-sso-operator.yaml&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- apiVersion: v1 kind: Namespace metadata: annotations: argocd.argoproj.io/sync-wave: "0" name: rhsso-prod spec: {} --- apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: annotations: argocd.argoproj.io/sync-wave: "1" name: rhsso-prod namespace: rhsso-prod spec: targetNamespaces: - rhsso-prod --- apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: annotations: argocd.argoproj.io/sync-wave: "2" name: rhsso-operator namespace: rhsso-prod spec: channel: stable installPlanApproval: Automatic name: rhsso-operator source: redhat-operators sourceNamespace: openshift-marketplace startingCSV: rhsso-operator.7.6.1-opr-005&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;But we have one new file &lt;code&gt;01_secret_rhsso-prod-database.yaml&lt;/code&gt;. This file is a secret containing the credentials for the external database.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat 01_secret_rhsso-prod-database.yaml &lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- apiVersion: v1 kind: Secret metadata: annotations: argocd.argoproj.io/sync-wave: "1" name: keycloak-db-secret namespace: rhsso-prod stringData: POSTGRES_DATABASE: "pgsql-rhsso-prod" POSTGRES_USERNAME: "pgsql-admin" POSTGRES_PASSWORD: "pgsql-password" POSTGRES_EXTERNAL_ADDRESS: "pgsql-database-url" POSTGRES_EXTERNAL_PORT: "5432" # of course we have to change the values to real ones&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And the new lines in our &lt;code&gt;03_deploy_rhsso-prod.yaml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat 03_deploy_rhsso-prod.yaml &lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- apiVersion: keycloak.org/v1alpha1 kind: Keycloak metadata: annotations: argocd.argoproj.io/sync-wave: "3" name: rhsso-prod labels: app: rhsso-prod namespace: rhsso-prod spec: multiAvailablityZones: enabled: true externalDatabase: # this one enabled: true #this one keycloakDeploymentSpec: imagePullPolicy: Always postgresDeploymentSpec: imagePullPolicy: Always instances: 2 storageClassName: gp2&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We can get the logs for one of the pods and check if it is running by using the command line or the GUI. We can see in the following log that it is up.&lt;/p&gt; &lt;pre&gt; &lt;code&gt;[0m[0m22:46:33,951 INFO [org.hibernate.annotations.common.Version] (ServerService Thread Pool -- 82) HCANN000001: Hibernate Commons Annotations {5.0.5.Final-redhat-00002} [0m[0m22:46:34,070 INFO [org.hibernate.dialect.Dialect] (ServerService Thread Pool -- 82) HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL95Dialect [0m[0m22:46:34,099 INFO [org.hibernate.engine.jdbc.env.internal.LobCreatorBuilderImpl] (ServerService Thread Pool -- 82) HHH000424: Disabling contextual LOB creation as createClob() method threw error : java.lang.reflect.InvocationTargetException [0m[0m22:46:34,102 INFO [org.hibernate.type.BasicTypeRegistry] (ServerService Thread Pool -- 82) HHH000270: Type registration [java.util.UUID] overrides previous : org.hibernate.type.UUIDBinaryType@33731349 [0m[0m22:46:34,106 INFO [org.hibernate.envers.boot.internal.EnversServiceImpl] (ServerService Thread Pool -- 82) Envers integration enabled? : true [0m[0m22:46:34,301 INFO [org.hibernate.orm.beans] (ServerService Thread Pool -- 82) HHH10005002: No explicit CDI BeanManager reference was passed to Hibernate, but CDI is available on the Hibernate ClassLoader. [0m[0m22:46:34,890 INFO [org.hibernate.validator.internal.util.Version] (ServerService Thread Pool -- 82) HV000001: Hibernate Validator 6.0.23.Final-redhat-00001 [0m[0m22:46:35,634 INFO [org.hibernate.hql.internal.QueryTranslatorFactoryInitiator] (ServerService Thread Pool -- 82) HHH000397: Using ASTQueryTranslatorFactory [0m[0m22:46:36,014 INFO [org.keycloak.services] (ServerService Thread Pool -- 82) KC-SERVICES0050: Initializing master realm [0m[0m22:46:36,744 INFO [org.keycloak.services] (ServerService Thread Pool -- 82) KC-SERVICES0006: Importing users from '/opt/eap/standalone/configuration/keycloak-add-user.json' [0m[0m22:46:37,010 INFO [org.keycloak.services] (ServerService Thread Pool -- 82) KC-SERVICES0009: Added user 'admin' to realm 'master'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Even if we try to change or delete any of the components like the single sign-on, the operator, or the namespace, Argo CD is going to redeploy according to the info on our Git repository.&lt;/p&gt; &lt;h2&gt;Deploying single sign-on is complete&lt;/h2&gt; &lt;p&gt;We have demonstrated how we can leverage Argo CD to not only deploy and define the state of our single sign-on instance, but also manage the state without any external interference or input. This can be done in a dev and production environment using a GitOps approach.&lt;/p&gt; &lt;p&gt;If you have questions, comment below. We welcome your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/10/how-deploy-single-sign-code-using-gitops" title="How to deploy single sign-on as code using GitOps"&gt;How to deploy single sign-on as code using GitOps&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Pablo Castelo, Ignacio Lago</dc:creator><dc:date>2023-04-10T07:00:00Z</dc:date></entry><entry><title>JBoss Tools 4.27.0.Final for Eclipse 2023-03</title><link rel="alternate" type="text/html" href="https://tools.jboss.org/blog/4.27.0.final.html" /><category term="release" /><category term="jbosstools" /><category term="jbosscentral" /><author><name>sbouchet</name></author><id>https://tools.jboss.org/blog/4.27.0.final.html</id><updated>2023-04-07T10:03:20Z</updated><published>2023-04-07T00:00:00Z</published><content type="html">&lt;div&gt;&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Happy to announce 4.27.0.Final build for Eclipse 2023-03.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Downloads available at &lt;a href="https://tools.jboss.org/downloads/jbosstools/2023-03/4.27.0.Final.html"&gt;JBoss Tools 4.27.0 Final&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-new"&gt;&lt;a class="anchor" href="#what-is-new"&gt;&lt;/a&gt;What is New?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Full info is at &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.27.0.Final.html"&gt;this page&lt;/a&gt;. Some highlights are below.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="general"&gt;&lt;a class="anchor" href="#general"&gt;&lt;/a&gt;General&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;We made several fixes in our server and javaee component to support jakarta namespaces.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="hibernate-tools"&gt;&lt;a class="anchor" href="#hibernate-tools"&gt;&lt;/a&gt;Hibernate Tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="runtime-provider-updates"&gt;&lt;a class="anchor" href="#runtime-provider-updates"&gt;&lt;/a&gt;Runtime Provider Updates&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 6.2 runtime provider now incorporates Hibernate Core version 6.2.0.CR4, Hibernate Ant version 6.2.0.CR4 and Hibernate Tools version 6.2.0.CR4.Final.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="and-more"&gt;&lt;a class="anchor" href="#and-more"&gt;&lt;/a&gt;And more…​&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can find more noteworthy updates in on &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.27.0.Final.html"&gt;this page&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Stéphane Bouchet&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;</content><summary>Happy to announce 4.27.0.Final build for Eclipse 2023-03. Downloads available at JBoss Tools 4.27.0 Final. What is New? Full info is at this page. Some highlights are below. General We made several fixes in our server and javaee component to support jakarta namespaces. Hibernate Tools Runtime Provider Updates The Hibernate 6.2 runtime provider now incorporates Hibernate Core version 6.2.0.CR4, Hibernate Ant version 6.2.0.CR4 and Hibernate Tools version 6.2.0.CR4.Final. And more…​ You can find more noteworthy updates in on this page. Enjoy! Stéphane Bouchet ...</summary><dc:creator>sbouchet</dc:creator><dc:date>2023-04-07T00:00:00Z</dc:date></entry><entry><title>Tips for handling localized ranges in regular expressions</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/06/tips-handling-rational-ranges-in-regular-expressions" /><author><name>Carlos O'Donell</name></author><id>6aac5134-349d-44f1-ba68-1d84eab780e0</id><updated>2023-04-06T07:00:00Z</updated><published>2023-04-06T07:00:00Z</published><summary type="html">&lt;p&gt;Developers as well as casual &lt;code&gt;grep&lt;/code&gt; users are accustomed to using ranges in &lt;a href="https://developers.redhat.com/articles/2022/09/14/beginners-guide-regular-expressions-grep"&gt;regular expressions&lt;/a&gt;, such as &lt;code&gt;[a-zA-Z]&lt;/code&gt; or &lt;code&gt;[0-9]&lt;/code&gt;. However, they often don't realize that these regular expressions harbor problems that can lead to unexpected behavior.&lt;/p&gt; &lt;p&gt;This article delves into the issues with using ranges in different locales and the solutions sought by developers of various libraries, including the GNU &lt;a href="https://developers.redhat.com/topics/c"&gt;C&lt;/a&gt; Library (glibc).&lt;/p&gt; &lt;h2&gt;The problem with regular expression ranges&lt;/h2&gt; &lt;p&gt;Under the &lt;a href="https://pubs.opengroup.org/onlinepubs/9699919799/xrat/V4_xbd_chap09.html"&gt;POSIX standard&lt;/a&gt;, a regular expression using a range expression has unspecified behavior in any locale other than the POSIX locale. This locale applies only to programs or environments whose environment variables for the locale (such as &lt;code&gt;LANG&lt;/code&gt; or &lt;code&gt;LC_ALL&lt;/code&gt;) specify either &lt;code&gt;POSIX&lt;/code&gt; or &lt;code&gt;C&lt;/code&gt;, or who don't have those environment variables set at all.&lt;/p&gt; &lt;p&gt;Of course, this hardly ever happens. Most people specify their country and language when setting up their system and get a locale such as &lt;code&gt;en_US.UTF-8&lt;/code&gt;, in this case, indicating U.S. English with UTF-8 characters.&lt;/p&gt; &lt;p&gt;For most programs and users, therefore, a popular regular expression range such as &lt;code&gt;[a-zA-Z]&lt;/code&gt; or &lt;code&gt;[0-9]&lt;/code&gt; has undefined and ultimately unreliable behavior. In theory, users should employ bracket expressions such as &lt;code&gt;[[:alpha:]]&lt;/code&gt; and &lt;code&gt;[[:digit:]]&lt;/code&gt;. In practice, it works as expected in many, but not all, locales.&lt;/p&gt; &lt;p&gt;What should a library do to support developers and make developing applications easier? We will explore current and upcoming solutions in the next sections.&lt;/p&gt; &lt;h2&gt;Possible solutions and their relationships to POSIX and Unicode&lt;/h2&gt; &lt;p&gt;There are a number of possible solutions. The support for ranges such as &lt;code&gt;[a-zA-Z]&lt;/code&gt; in the C (POSIX) locale is a clue that support for the ranges was implemented by early C libraries when ASCII was the norm. Although there are many conflicting solutions, each generally maps to one of the following implementations:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Native character order (NCO):&lt;/strong&gt; This means that a developer looking at a code chart for the character set can logically identify all characters in the range by reviewing, in order, those characters in the code chart from the start of the range to the end of the range.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Collation element order (CEO):&lt;/strong&gt; This means that a developer looking at the locale sources for the current locale can logically identify all characters in the range by reviewing, in order, those characters in the &lt;a href="https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap07.html"&gt;&lt;code&gt;LC_COLLATE&lt;/code&gt;&lt;/a&gt; definition in the POSIX locale sources (later compiled into the binary locale on your system, e.g., &lt;code&gt;en_US.UTF-8&lt;/code&gt;) from the start of the range to the end of the range.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Collation sequence order (CSO):&lt;/strong&gt; This means that a developer looking at, for one definition of a natural language order, a dictionary with said natural language order can logically identify all characters in the range by reviewing, in order, those characters in the dictionary from the start of the range to the end of the range.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;For example, in the article &lt;a href="https://www.boost.org/doc/libs/1_38_0/libs/regex/doc/html/boost_regex/syntax/basic_extended.html"&gt;Boost C++ POSIX regular extended expression APIs&lt;/a&gt;, the authors implemented CSO with an &lt;a href="https://www.boost.org/doc/libs/1_38_0/libs/regex/doc/html/boost_regex/ref/syntax_option_type/syntax_option_type_extended.html"&gt;option&lt;/a&gt; to fall back to NCO. As another example, the &lt;a href="https://www.gnu.org/software/gawk/manual/html_node/Regexp.html"&gt;GNU Awk (Gawk) implementation&lt;/a&gt; has two modes: a "traditional" mode that emulates NCO within certain ASCII ranges and a POSIX-based mode that emulates CSO. The Boost and Gawk implementations offer a very similar degree of choice between NCO and CSO.&lt;/p&gt; &lt;p&gt;In glibc, the implementation is based on the early POSIX specifications that required CEO. In the built-in C and POSIX locale, the NCO and CEO are equivalent because the ASCII character set order can be ordered the same as the collation elements in the locale source specification. The glibc locale for &lt;code&gt;en_US.UTF-8&lt;/code&gt; makes the NCO and CEO equivalent for lowercase Latin characters, uppercase Latin characters, and numbers in order to preserve developer expectations for sorting these ranges; e.g., lowercase Latin characters are not interleaved with uppercase Latin characters.&lt;/p&gt; &lt;p&gt;CEO and CSO require large element lists and thus add a lot more overhead to implementations than NCO.&lt;/p&gt; &lt;p&gt;The published &lt;a href="https://www.iso.org/standard/68309.html"&gt;ISO 14651 (2020) standard&lt;/a&gt;, most recently derived from Unicode 13.0.0 (2020), defines the international string ordering and comparison, and glibc uses this standard as the basis for string collation. The &lt;a href="https://unicode-org.github.io/icu/userguide/collation/"&gt;collation element ordering&lt;/a&gt; in the ISO standard interleaves lowercase and uppercase characters in such a way that CEO is more aligned to logical groups of letters e.g. A and a, instead of NCO. Direct usage of ISO 14651 in glibc &lt;a href="https://sourceware.org/bugzilla/show_bug.cgi?id=23393"&gt; caused regressions&lt;/a&gt; due to this grouping; e.g., &lt;code&gt;[a-z]&lt;/code&gt; would match &lt;code&gt;A&lt;/code&gt; unexpectedly.&lt;/p&gt; &lt;h2&gt;Current and upcoming solutions&lt;/h2&gt; &lt;p&gt;Boost's interface allows one to choose between a logical NCO or CSO (as defined for a single natural language ordering), thus offering two of three solutions listed in the previous section. A user who desires a distinct CEO can create a completely new locale source definition and distribute that to users that want a distinct ordering. Thread-safe locale APIs can be used to set and use the locale on a per-thread basis.&lt;/p&gt; &lt;p&gt;The APIs implemented by the ICU project support many possible CSOs for a given language, including dictionary sort, address book sort, calendar sort, etc. No single CSO will solve the needs of all users.&lt;/p&gt; &lt;p&gt;The glibc implementation of CEO does not meet the needs of developers who are either looking at a code chart or applying common-sense logic to natural language ordering. Migrating glibc from CEO to CSO seems like a logical way forward, but the internal implementation will need to be significantly improved to support this transition. The most straightforward first step is a &lt;a href="https://sourceware.org/bugzilla/show_bug.cgi?id=17318"&gt;C.UTF-8 that uses NCO in glibc&lt;/a&gt; and avoids the overhead of CEO or CSO.&lt;/p&gt; &lt;p&gt;With the release of glibc 2.35 in February 2022, the project now has an official harmonized and C.UTF-8 that will use NCO for ASCII regular expression ranges and NCO for collation (code-point collation order).&lt;/p&gt; &lt;p&gt;You can already use this new C.UTF-8 locale in Fedora (starting with Fedora 35).  In the future, C.UTF-8 will be &lt;a href="https://sourceware.org/bugzilla/show_bug.cgi?id=28255"&gt;extended to allow rational ranges that cover all code points in NCO&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/06/tips-handling-rational-ranges-in-regular-expressions" title="Tips for handling localized ranges in regular expressions"&gt;Tips for handling localized ranges in regular expressions&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Carlos O'Donell</dc:creator><dc:date>2023-04-06T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - April, 06 2023</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2023-04-06.html" /><category term="quarkus" /><category term="vertx" /><category term="java" /><category term="wildfly" /><category term="keycloak" /><author><name>Don Naro</name><uri>https://www.jboss.org/people/don-naro</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2023-04-06.html</id><updated>2023-04-06T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, vertx, java, wildfly, keycloak"&gt; &lt;h1&gt;This Week in JBoss - April, 06 2023&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hi, how are you? Welcome back to another edition of the JBoss Editorial with exciting news and updates from your JBoss communities.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Here are the most recent releases for this edition:&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-3-0-0-cr1-released/"&gt;Quarkus 3.0.0 CR1&lt;/a&gt; and &lt;a href="https://quarkus.io/blog/quarkus-3-0-0-cr2-released/"&gt;Quarkus 3.0.0 CR2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://vertx.io/blog/eclipse-vert-x-4-4-1/"&gt;Eclipse Vert.x 4.4.1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2023/03/keycloak-2102-released"&gt;Keycloak 21.0.2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org//news/2023/03/30/WildFly28-Beta-Released/"&gt;WildFly 28 Beta1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_debugging_restassured_tests"&gt;Debugging RestAssured Tests&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://www.mastertheboss.com/various-stuff/testing-java/debugging-restassured-tests/"&gt;Debugging RestAssured Tests&lt;/a&gt;, by Francesco Marchioni&lt;/p&gt; &lt;p&gt;Anyone running REST Assured tests has probably run into errors such as failing assertions or incorrect responses. If that is the case for you, then this article from Francesco will no doubt be valuable as he explains some solid techniques for debugging that quickly identify root causes and save you time getting things fixed.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_extending_the_life_of_keycloak_adapters"&gt;Extending the life of Keycloak adapters&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2023/03/adapter-deprecation-update"&gt;Update on deprecation of Keycloak adapters&lt;/a&gt;, by Stian Thorgersen&lt;/p&gt; &lt;p&gt;Following up on the announcement to deprecate Keycloak adapters, Stian has provided an udpate on what the future holds for the adapters.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_cross_resource_sharing_on_wildfly"&gt;Cross resource sharing on WildFly&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/web/jboss-web-server/how-to-configure-cors-on-wildfly/"&gt;How to configure CORS on WildFly&lt;/a&gt;, by Francesco Marchioni&lt;/p&gt; &lt;p&gt;Francesco delivers another insightful tutorial that quickly gets WildFly set up for cross-domain requests.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_video_corner"&gt;Video corner&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Check out some recent awesome YouTube videos from the community.&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/i8nHKmGxGuM"&gt;Getting Started with Accessing Your Application Portfolio&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/live/82NjJ7gDzv0"&gt;Quarkus Insights #124: 1000 ways to deploy Quarkus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/live/cU-2witNthQ"&gt;Quarkus Insights #123: 10 things I like about Quarkus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/3zzkGiVW7p8"&gt;Getting started with Ansible for Application Services&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/HKcrtQuWimY"&gt;Boosting Engineering Efficiency with OpenTelemetry, Keptn &amp;#38; Tyk&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;&lt;em&gt;That’s all folks! Please join us again in two weeks for another round of our JBoss editorial!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/don-naro.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Don Naro&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Don Naro</dc:creator></entry></feed>
